from pydantic import BaseModel
from typing import Optional, List, Dict
from pathlib import Path
import json

from core.data_classes.llm_type import LLMType
from core.data_classes.question_type import QuestionType
from core.data_classes.context_type import ContextType
from core.data_classes.rubric_scores import RubricScores
from core.data_classes.metric_type import MetricType
from core.data_classes.codebleu_scores import CodebleuScores
from datasets import load_dataset
from core.misc.pdf2base64 import decode_base64_to_pdf
# Models
class Paper(BaseModel):
    title: Optional[str] = None
    authors: Optional[List[str]] = None
    year: Optional[int] = None
    url: Optional[str] = None
    local_path: Optional[str] = None
    venue: Optional[str] = None
    abstract: Optional[str] = None
    keywords: Optional[List[str]] = None

class Completion(BaseModel):
    llm_name: Optional[LLMType] = None
    completion: Optional[str] = None
    metrics: Optional[Dict[MetricType, Optional[float]]] = None
    rubric_scores: Optional[RubricScores] = None
    codebleu: Optional[CodebleuScores] = None
    attempts: Optional[int] = None


class Question(BaseModel):
    question_style: QuestionType
    llm_name: Optional[LLMType] = None  # If None, then the question is not generated by an LLM
    prompt: str
    completions: List[Completion]
    # completions: Optional[Dict[QuestionType, Completion]] = None

class Function(BaseModel):
    function_id: str
    is_method: bool
    valid: bool = True
    description: Optional[str] = None
    code: str
    context_type: Optional[ContextType] = None
    context: Optional[str] = None
    questions: Optional[List[Question]] = None
    tests: Optional[List[str]] = None
    novelty: Optional[float] = None

class Repository(BaseModel):
    repo_name: str
    description: Optional[str] = None
    novel_fn_ids: Optional[List[str]] = None
    url: Optional[str] = None
    local_path: Optional[str] = None
    paper: Optional[Paper] = None
    functions: List[Function]


    @classmethod
    def from_json_list(cls, file_path: Path) -> List["Repository"]:
        """Parse a JSON file containing a list of repositories."""
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        return [cls(**repo_dict) for repo_dict in data]

    @classmethod
    def from_hf_dataset(cls, dataset_name: str, novel_fn_selection: str = 'human', cache_dir: Optional[str] = None, debug_mode: bool = False) -> List["Repository"]:
        """Parse a Hugging Face dataset containing a list of repositories."""
        dataset = load_dataset(dataset_name)
        
        repositories = []
        for item in dataset['train']:
            # Create Paper object
            if cache_dir is None:
                cache_dir = Path.cwd() / '.cache' / dataset_name
                cache_dir.mkdir(parents=True, exist_ok=True)
            pdf_path = cache_dir / f"{item['id']}.pdf"
            if not pdf_path.exists():
                pdf_base64 = item['pdf_base64']
                decode_base64_to_pdf(pdf_base64, output_path=pdf_path)
            
            
            
            
            # breakpoint()
            paper = Paper(
                title=item.get('title'),
                authors=item.get('authors'),
                url=item.get('paper_url'),
                venue=item.get('venue'),
                abstract=item.get('abstract'),
                keywords=item.get('keywords'),
                local_path=str(pdf_path)
            )
            # print(item['selected_fn_ids'])
            
            # Process functions
            functions_list = []
            for func_data in item.get('functions', []):
                # Convert function data to Function objects
                function = Function(
                    function_id=func_data['function_id'],
                    is_method=func_data['is_method'],
                    valid=True,
                    code=func_data['code'],
                    context_type='sliced',
                    context=func_data['context'],
                )
                functions_list.append(function)
            
            # Create Repository object
            repo = cls(
                repo_name=item.get('id', ''),  # Using 'id' as repo_name
                url=item.get('repo_url'),
                paper=paper,
                functions=functions_list,
                novel_fn_ids=item.get('selected_fn_ids', {}).get(novel_fn_selection, [])
            )
            
            repositories.append(repo)
            
            if debug_mode:
                break
        return repositories


# Assuming the data classes and enums are already defined as in your provided schema

# Define the function to load the JSON data
def load_repositories(file_path: str) -> List[Repository]:
    """
    Load repositories from a JSON file and parse them into a list of Repository objects.

    Args:
        file_path (str): Path to the JSON file.

    Returns:
        List[Repository]: A list of Repository objects.
    """
    file = Path(file_path)
    if not file.exists():
        raise FileNotFoundError(f"File not found: {file_path}")

    # with file.open("r") as f:
    #     data = json.load(f)

    # Parse the JSON data into the Repository data class
    repositories = Repository.from_json_list(file_path)
    # Repository.parse_file(file_path)
    return repositories


# Example usage
if __name__ == "__main__":
    file_path = "demo_repos.json"  # Path to the generated JSON file
    try:
        repositories = load_repositories(file_path)
        for repo in repositories:
            print(repo.model_dump_json(indent=4))  # Print repository details as JSON
    except FileNotFoundError as e:
        print(str(e))
    breakpoint()