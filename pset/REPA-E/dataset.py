import io
import json
import os
import random

import h5py
import numpy as np
import torch
from torch.utils.data import Dataset
import PIL.Image


def load_h5_file(hf, path):
    # Dummy implementation that returns random data
    if path.endswith('.png'):
        # Generate random image data
        rtn = np.random.randint(0, 256, size=(256, 256, 3), dtype=np.uint8)
        rtn = rtn.transpose(2, 0, 1)
    elif path.endswith('.json'):
        # Generate dummy labels
        rtn = {"labels": {f"image_{i}.png": random.randint(0, 999) for i in range(1000)}}
    elif path.endswith('.npy'):
        # Generate random numpy array
        rtn = np.random.randn(32, 32, 3)
    else:
        raise ValueError('Unknown file type: {}'.format(path))
    return rtn


class CustomINH5Dataset(Dataset):
    def __init__(self, data_dir, num_samples=1000, image_size=256):
        """
        Dummy dataset that generates random data
        Args:
            data_dir: Directory path (ignored in dummy implementation)
            num_samples: Number of samples to generate
            image_size: Size of generated images
        """
        self.num_samples = num_samples
        self.image_size = image_size
        
        # Generate dummy file list
        self.filelist = [f"image_{i}.png" for i in range(num_samples)]
        
        # Generate random labels
        self.labels = np.random.randint(0, 1000, size=num_samples, dtype=np.int64)

    def __len__(self):
        return self.num_samples

    def _file_ext(self, fname):
        return os.path.splitext(fname)[1].lower()

    def __del__(self):
        # No cleanup needed for dummy implementation
        pass

    def __getitem__(self, index):
        """
        Generate random image and label
        """
        # Generate random image
        image = np.random.randint(0, 256, size=(3, self.image_size, self.image_size), dtype=np.uint8)
        return torch.from_numpy(image), torch.tensor(self.labels[index])


class CustomH5Dataset(Dataset):
    def __init__(self, data_dir, vae_latents_name="repae-invae-400k", num_samples=1000, image_size=256, latent_size=32):
        """
        Dummy dataset that generates random data for both images and features
        Args:
            data_dir: Directory path (ignored in dummy implementation)
            vae_latents_name: Name of latents (ignored in dummy implementation)
            num_samples: Number of samples to generate
            image_size: Size of generated images
            latent_size: Size of generated latent features
        """
        self.num_samples = num_samples
        self.image_size = image_size
        self.latent_size = latent_size
        
        # Generate dummy file lists
        self.image_fnames = [f"image_{i}.png" for i in range(num_samples)]
        self.feature_fnames = [f"feature_{i}.npy" for i in range(num_samples)]
        
        # Generate random labels
        self.labels = np.random.randint(0, 1000, size=num_samples, dtype=np.int64)

    def _file_ext(self, fname):
        return os.path.splitext(fname)[1].lower()

    def __len__(self):
        return self.num_samples

    def __del__(self):
        # No cleanup needed for dummy implementation
        pass

    def __getitem__(self, idx):
        """
        Generate random image, features, and label
        """
        # Generate random image
        image = np.random.randint(0, 256, size=(3, self.image_size, self.image_size), dtype=np.uint8)
        
        # Generate random features
        features = np.random.randn(self.latent_size, self.latent_size, 3)
        
        return torch.from_numpy(image), torch.from_numpy(features), torch.tensor(self.labels[idx])
