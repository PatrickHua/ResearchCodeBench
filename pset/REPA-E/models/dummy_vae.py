import torch
import torch.nn as nn
import numpy as np

class DummyDiagonalGaussianDistribution:
    def __init__(self, parameters, deterministic=False):
        self.parameters = parameters
        self.mean, self.logvar = torch.chunk(parameters, 2, dim=1)
        self.logvar = torch.clamp(self.logvar, -30.0, 20.0)
        self.deterministic = deterministic
        self.std = torch.exp(0.5 * self.logvar)
        self.var = torch.exp(self.logvar)
        if self.deterministic:
            self.var = self.std = torch.zeros_like(self.mean).to(
                device=self.parameters.device
            )

    def sample(self):
        x = self.mean + self.std * torch.randn(self.mean.shape, device=self.parameters.device)
        return x

    def kl(self, other=None):
        if self.deterministic:
            return torch.Tensor([0.0])
        else:
            if other is None:
                return 0.5 * torch.sum(
                    torch.pow(self.mean, 2) + self.var - 1.0 - self.logvar,
                    dim=[1, 2, 3],
                )
            else:
                return 0.5 * torch.sum(
                    torch.pow(self.mean - other.mean, 2) / other.var
                    + self.var / other.var
                    - 1.0
                    - self.logvar
                    + other.logvar,
                    dim=[1, 2, 3],
                )

    def nll(self, sample, dims=[1, 2, 3]):
        if self.deterministic:
            return torch.Tensor([0.0])
        logtwopi = np.log(2.0 * np.pi)
        return 0.5 * torch.sum(
            logtwopi + self.logvar + torch.pow(sample - self.mean, 2) / self.var,
            dim=dims,
        )

    def mode(self):
        return self.mean

class DummyVAE(nn.Module):
    def __init__(self, embed_dim, ch_mult, use_variational=True):
        super().__init__()
        self.embed_dim = embed_dim
        self.use_variational = use_variational

    def encode(self, x):
        # Create random moments with correct shape
        # For f8d4: [B, 8, H/8, W/8]
        # For f16d32: [B, 64, H/16, W/16]
        B, C, H, W = x.shape
        if self.embed_dim == 4:  # f8d4
            h = H // 8
            w = W // 8
            moments = torch.randn(B, 8, h, w, device=x.device)
        else:  # f16d32
            h = H // 16
            w = W // 16
            moments = torch.randn(B, 64, h, w, device=x.device)
        posterior = DummyDiagonalGaussianDistribution(moments)
        return posterior

    def decode(self, z):
        # Return random image with same shape as input
        B, C, H, W = z.shape
        if self.embed_dim == 4:  # f8d4
            recon = torch.randn(B, 3, H*8, W*8, device=z.device)
        else:  # f16d32
            recon = torch.randn(B, 3, H*16, W*16, device=z.device)
        return {"sample": recon}

    def forward(self, x, return_recon=True):
        posterior = self.encode(x)
        z = posterior.sample()

        recon = None
        if return_recon:
            recon = self.decode(z)["sample"]
        return posterior, z, recon

def DummyVAE_F8D4(**kwargs):
    return DummyVAE(embed_dim=4, ch_mult=[1, 2, 4, 4], use_variational=True, **kwargs)

def DummyVAE_F16D32(**kwargs):
    return DummyVAE(embed_dim=32, ch_mult=[1, 1, 2, 2, 4], use_variational=True, **kwargs)

dummy_vae_models = {
    "f8d4": DummyVAE_F8D4,
    "f16d32": DummyVAE_F16D32,
} 